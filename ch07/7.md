# 七、The VC Dimension VC维

## 7.1 Definition of VC Dimension VC维的定义

先对上一章的内容作简单总结：如果一个假设空间存在突破点。则一定存在成长函数$m_H(N)$被某个上限函数$B(N,k)$所约束，可求出上限函数等于一个组合的求和形式$\sum_{i=0}^{k-1}C_N^i$，易知该形式的最高次项是$N^{k-1}$。图7-1a)和b）分别是以上限函数为成长函数上限的情况和以为成长函数上限的情况。

<div align='center'><img src='http://i4.bvimg.com/602813/c86d080e03347f3b.png'>
<img src='http://i1.bvimg.com/602813/e133bb9e2e1ce171.png'></div>
<center>图7-1 a) 以上限函数为上限 b) 以$N^{k-1}$为上限
 </center>
 从图中可以看出在$N \ge 2$ 且 $K \ge 3$的情况下，满足$B(N,k) \le N{K-1}$，得到公式7-1。
 $$
 m_H(N) = B(N,k) = \sum_{i=0}^{k-1}C_N^i \le N^{k-1}
 $$

 通过公式7-1和上一章的结论可以得出公式7-2。
 $$
 \begin{aligned}
 P_D[|E_{in}(g) - E_{out}(g)| > \varepsilon]
&\le P_D[\exists h \in s.t. |E_{in} - E_{out}| > \varepsilon] \\
&\le 4m_H(2N)\exp(-\frac{1}{8}\varepsilon^2N) \\
&\le^{\text{if K exists}} 4N^{k-1}\exp(-\frac{1}{8}\varepsilon^2N)
 \end{aligned}
 $$

该公式的意义是在输入样本N很大时，VC限制一定成立，同时等式的左边也一定会在$k \ge 3$ 的情况下被以多项式形式（$N^{k-1}$）所约束（注意这里$N \ge 2$的条件没有了，原因很简单，VC限制是样本N很大的情况下产生的，因此一定满足$N \ge 2$的条件），而在k<3的情况下有其他的限制可以满足（比如前几章提到的如正射线之类的分类不需要多项式形式的限制也可以约束住成长函数）。

至此得知，满足以下几个条件，机器便可以学习：

1. 假设空间的成长函数有一个突破点k（有好的假设空间H）；
2. 输入数据样本N足够的大（有好的输入样本集D）；

1和2通过VC限制共同推出了$E_{in}$和$E_{out}$有很大的可能很接近。

1. 一个算法A能够找出一个使 $E_{in}$ 足够小的g（好的算法A）；

再结合1和2得出的结论就可以进行学习了（当然这里需要一点好的运气）。

接下来介绍一下这一节的正题，VC维度或者VC维（VC dimension）是什么意思。

它的定义和突破点（break point）有很大关系，是最大的一个不是突破点的数。

VC维是假设空间的一个性质，数据样本可以被完全二分的最大值。用$d_{VC}$作为VC维的数学符号，假如突破点存在的话，即最小的突破点减去1，如公式7-3所示；如果不存在突破点的话，则VC维为无限大。
$$d_{VC} = '\text{最小的}k' -1$$

如果输入数据量N小于VC维$d_{VC}$，则有可能输入数据D会被完全的二分类，这里不是一定，只能保证存在。

如果输入数据量N（或者用k表示）大于VC维$d_{VC}$，则有k一定是假设空间H的突破点。

使用VC维$d_{VC}$对公式7-1进行重写，在$N \ge 2$ 且$ d_{VC} ge 2$时，如公式7-4所示。
$$
m_H(N) \le N^{d_{VC}}
$$
对第五章中提到的几种分类，使用VC维取代突破点，表示VC维与成长函数的关系，如表7-1所示。
<div align='center'><img src='http://i2.bvimg.com/602813/04abb29b024411b1.png'></div>

对上述条件1中好的假设空间重新做一个定义，**即有限的VC维$d_{VC}$**。

一个有限的VC维总是能够保证寻找到的近似假设g满足$E_{in}(g) \approx E_{out}(g)$，这一结论与下述部分没有关系：

1. 使用的算法A，即使很大$E_{in}(g)$，也依然能满足上述的性质；
2. 输入数据的分布P；
3. 未知的目标函数f。

即VC维可应对任意的假设空间，任意的数据分布情况，任意的目标函数。

满足这一性质可以得到如图7-2所示的流程图，其中灰色的部分表示上述几个不会影响$E_{in}(g) \approx E_{out}(g)$这一结果的部分。
<div align='center'><img src='http://i1.bvimg.com/602813/b3100a7ebd857ceb.png'></div>
<center>图7-2 由VC维保证机器可以学习的流程图</center>

## 7.2 VC Dimension of Perceptrons